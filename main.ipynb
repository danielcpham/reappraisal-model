{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reappraisal Training For Linguistic Distancing and Emotion Regulation\n",
    "\n",
    "\n",
    "## Setup\n",
    "```bash\n",
    "> pipenv shell  #Generates a new virtual environment based on Pipfile\n",
    "> pipenv install # Installs the packages in Pipfile.lock (Use --dev) to also install dev packages\n",
    "```\n",
    "## Included Datasets\n",
    "- LDHII \n",
    "- \n",
    "- Emobank\n",
    "**Sources**\n",
    "-  [Sentiment Analysis Text Classification Tutorial](https://www.youtube.com/watch?v=8N-nM3QW7O0)\n",
    "- [Using Catalyst for Training Organization](https://github.com/catalyst-team/catalyst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Uncomment to add the src code to the working dir when on colab\n",
    "# ! git init\n",
    "# ! git config core.sparseCheckout true\n",
    "# ! git remote add -f origin https://github.com/danielcpham/reappraisal-model.git\n",
    "# ! echo \"src/\" > .git/info/sparse-checkout\n",
    "# ! echo \"poetry.lock\" >> .git/info/sparse-checkout\n",
    "# ! echo \"pyproject.toml\" >> .git/info/sparse-checkout \n",
    "# ! git checkout dev\n",
    "\n",
    "# ! pip install transformers datasets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "# !pipenv install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, running on CPU\n"
     ]
    }
   ],
   "source": [
    "from datasets import ReadInstruction\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Enable GPU usage, if we can.\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Enabling GPU usage\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    IS_GPU = True\n",
    "else:\n",
    "    print(\"No GPU available, running on CPU\")\n",
    "    device = torch.device(\"cpu\") # Note: macOS incompatible with NVIDIA GPUs\n",
    "    IS_GPU = False\n",
    "    \n",
    "# Constants and environment setup\n",
    "# TODO: Set up env files for dev and \"prod\"\n",
    "#Casing can matter for sentiment analysis (\"bad\" vs. \"BAD\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "\n",
    "tokenize_func = lambda batch: tokenizer(\n",
    "    batch['response'],\n",
    "    add_special_tokens=True,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True)\n",
    "\n",
    "PRETRAINED_MODEL_NAME = 'distilbert-base-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDH Dataset Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.LDHData import LDHData\n",
    "\n",
    "data = LDHData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB Dataset Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmoBank Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6496af81627a492884a8695ac0e779f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=842.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788904e4e6464f299b074ee141ccd74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=842.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7547e14804e64b108c6bc3942c5d415c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1436.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18153a9559db44d4bee8ab4eebcc3725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1436.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': DatasetDict({\n",
       "     far: Dataset({\n",
       "         features: ['attention_mask', 'input_ids', 'response', 'score'],\n",
       "         num_rows: 13470\n",
       "     })\n",
       "     obj: Dataset({\n",
       "         features: ['attention_mask', 'input_ids', 'response', 'score'],\n",
       "         num_rows: 13470\n",
       "     })\n",
       " }),\n",
       " 'eval': DatasetDict({\n",
       "     far: Dataset({\n",
       "         features: ['__index_level_0__', 'addcode', 'attention_mask', 'input_ids', 'level_0', 'response'],\n",
       "         num_rows: 22972\n",
       "     })\n",
       "     obj: Dataset({\n",
       "         features: ['__index_level_0__', 'addcode', 'attention_mask', 'input_ids', 'level_0', 'response'],\n",
       "         num_rows: 22972\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "from datasets import Features, Sequence, Value, DatasetDict\n",
    "# Tokenize the datasets.\n",
    "# Add score to the model inputs so we can calculate loss.\n",
    "\n",
    "# encoded_ds = data.encode(tokenizer, train_ds)\n",
    "\n",
    "# encoded_ds['train'].features\n",
    "# data.set_tokenizer(tokenizer)\n",
    "# train_ds = data.get_train_far_data()\n",
    "\n",
    "encoded_ds = data.encode_datasets(tokenizer, batched=True, batch_size=16)\n",
    "encoded_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22972\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DistilBertModel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.ReappModel import ReappModel\n",
    "\n",
    "# Create the training model.\n",
    "# TODO: Suppress initialization errors.\n",
    "model = ReappModel(DistilBertModel, PRETRAINED_MODEL_NAME)\n",
    "\n",
    "num_train_epochs = 3 if IS_GPU else 1\n",
    "\n",
    "# Define the parameters under which the model will be trained.\n",
    "# By default, uses an AdamW optimizer w/ linear warmup.\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    ")\n",
    "encoded_train = encoded_ds['train']['far']\n",
    "encoded_eval  = encoded_ds['eval']['far']\n",
    "\n",
    "print(len(encoded_eval))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,                  \n",
    "    train_dataset=encoded_train,      \n",
    "    eval_dataset=encoded_eval         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2437e+09)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_step = encoded_train.select(range(16))\n",
    "input_ids = encoded_train_step['input_ids']\n",
    "attention_mask = encoded_train_step['attention_mask']\n",
    "score = encoded_train_step['score'],\n",
    "\n",
    "trainer.training_step(model, {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": attention_mask,\n",
    "    \"score\": score\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation: Parse the TrainOutput Object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " (tensor(1.2421e+09),\n",
       "  tensor([[0.3158, 0.1279, 0.0000,  ..., 0.0000, 0.1537, 0.0000],\n",
       "          [0.0800, 0.0000, 0.4360,  ..., 0.0000, 0.2885, 0.0000],\n",
       "          [0.1454, 0.0000, 0.0957,  ..., 0.0000, 0.2639, 0.1835],\n",
       "          ...,\n",
       "          [0.3524, 0.0000, 0.0000,  ..., 0.0000, 0.3172, 0.0000],\n",
       "          [0.3425, 0.0000, 0.0000,  ..., 0.0401, 0.3588, 0.0000],\n",
       "          [0.4287, 0.1626, 0.0000,  ..., 0.0000, 0.3991, 0.0000]]),\n",
       "  tensor([[0.2471, 0.0000, 0.0000,  ..., 0.0000, 0.1829, 0.0379],\n",
       "          [0.1583, 0.0000, 0.0000,  ..., 0.1005, 0.4503, 0.1924],\n",
       "          [0.0000, 0.0000, 0.2992,  ..., 0.0000, 0.0188, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0624, 0.1866, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0529, 0.2066, 0.0000],\n",
       "          [0.0388, 0.0000, 0.0000,  ..., 0.0855, 0.1923, 0.0000]]),\n",
       "  tensor([[0.0262, 0.0000, 0.0235,  ..., 0.0297, 0.2659, 0.0000],\n",
       "          [0.0000, 0.0000, 0.2048,  ..., 0.0905, 0.3916, 0.0000],\n",
       "          [0.0000, 0.0000, 0.3661,  ..., 0.4366, 0.4765, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.1439, 0.2893, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.1255, 0.2097, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.1241, 0.3264, 0.0000]]),\n",
       "  tensor([[0.2765, 0.0685, 0.0000,  ..., 0.0000, 0.1275, 0.0000],\n",
       "          [0.0000, 0.2342, 0.0000,  ..., 0.1484, 0.0742, 0.0000],\n",
       "          [0.0000, 0.0823, 0.1535,  ..., 0.1629, 0.1536, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0033, 0.1897, 0.0000],\n",
       "          [0.1108, 0.0054, 0.0000,  ..., 0.0000, 0.1509, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2656, 0.0000]]),\n",
       "  tensor([[0.2511, 0.0000, 0.0000,  ..., 0.0000, 0.1432, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0286,  ..., 0.0896, 0.5138, 0.0874],\n",
       "          [0.0399, 0.0000, 0.0000,  ..., 0.0000, 0.3395, 0.2349],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0279, 0.2048, 0.0000],\n",
       "          [0.0151, 0.0000, 0.0450,  ..., 0.0423, 0.1712, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.1496, 0.0642, 0.0000]]),\n",
       "  tensor([[0.4028, 0.0938, 0.0000,  ..., 0.0000, 0.0717, 0.0000],\n",
       "          [0.1439, 0.0828, 0.0000,  ..., 0.0666, 0.0549, 0.0000],\n",
       "          [0.0066, 0.2087, 0.0000,  ..., 0.1045, 0.0000, 0.0744],\n",
       "          ...,\n",
       "          [0.0401, 0.0152, 0.0000,  ..., 0.1433, 0.0000, 0.0000],\n",
       "          [0.0488, 0.0986, 0.0000,  ..., 0.2399, 0.0454, 0.0185],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.2092, 0.0000, 0.0000]]),\n",
       "  tensor([[0.3401, 0.0000, 0.0000,  ..., 0.0000, 0.0104, 0.0772],\n",
       "          [0.0000, 0.0870, 0.0000,  ..., 0.5563, 0.5033, 0.0000],\n",
       "          [0.1839, 0.0699, 0.2251,  ..., 0.0332, 0.1930, 0.0000],\n",
       "          ...,\n",
       "          [0.1244, 0.0919, 0.0000,  ..., 0.1342, 0.0000, 0.0000],\n",
       "          [0.1960, 0.0533, 0.0000,  ..., 0.1474, 0.0000, 0.0000],\n",
       "          [0.1539, 0.0333, 0.0000,  ..., 0.1039, 0.0000, 0.0000]]),\n",
       "  tensor([[0.1420, 0.0000, 0.0000,  ..., 0.0000, 0.1555, 0.0000],\n",
       "          [0.0120, 0.0000, 0.0000,  ..., 0.0837, 0.2925, 0.0000],\n",
       "          [0.1245, 0.0000, 0.1277,  ..., 0.3023, 0.4686, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0067, 0.0000,  ..., 0.0000, 0.1681, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1232, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0173, 0.0000]]),\n",
       "  tensor([[0.1984, 0.0240, 0.0000,  ..., 0.0000, 0.2358, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5281, 0.0000],\n",
       "          [0.0506, 0.0000, 0.2291,  ..., 0.2758, 0.2659, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3113, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2551, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1881, 0.0000]]),\n",
       "  tensor([[0.2545, 0.0000, 0.0287,  ..., 0.0000, 0.3314, 0.2409],\n",
       "          [0.2285, 0.0000, 0.0856,  ..., 0.0519, 0.3125, 0.0000],\n",
       "          [0.1410, 0.0000, 0.5742,  ..., 0.3296, 0.1424, 0.1337],\n",
       "          ...,\n",
       "          [0.0776, 0.0000, 0.0227,  ..., 0.2200, 0.4313, 0.0000],\n",
       "          [0.0223, 0.0000, 0.0784,  ..., 0.0961, 0.3874, 0.0698],\n",
       "          [0.0000, 0.0000, 0.0346,  ..., 0.1054, 0.3732, 0.0144]]),\n",
       "  tensor([[0.1170, 0.0000, 0.0000,  ..., 0.0000, 0.1606, 0.0103],\n",
       "          [0.3278, 0.0000, 0.4528,  ..., 0.0000, 0.6060, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.1102, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.2731, 0.0000,  ..., 0.0214, 0.1002, 0.0000],\n",
       "          [0.0000, 0.3163, 0.0706,  ..., 0.1198, 0.0970, 0.0000],\n",
       "          [0.0000, 0.2941, 0.0000,  ..., 0.1934, 0.0293, 0.0000]]),\n",
       "  tensor([[0.0245, 0.0000, 0.0260,  ..., 0.0000, 0.2934, 0.0000],\n",
       "          [0.1223, 0.0000, 0.0000,  ..., 0.1555, 0.5684, 0.0000],\n",
       "          [0.0000, 0.0000, 0.5588,  ..., 0.3278, 0.2782, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3771, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2476, 0.0084],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0160, 0.2611, 0.0429]]),\n",
       "  tensor([[0.2510, 0.1090, 0.0000,  ..., 0.0000, 0.2175, 0.0000],\n",
       "          [0.0000, 0.0300, 0.0000,  ..., 0.1712, 0.2100, 0.0000],\n",
       "          [0.0000, 0.0000, 0.2187,  ..., 0.2492, 0.7011, 0.1587],\n",
       "          ...,\n",
       "          [0.0000, 0.3201, 0.0000,  ..., 0.2228, 0.2998, 0.0000],\n",
       "          [0.0000, 0.0084, 0.0000,  ..., 0.3089, 0.3831, 0.0000],\n",
       "          [0.0561, 0.1659, 0.0000,  ..., 0.2884, 0.3419, 0.0000]]),\n",
       "  tensor([[0.4075, 0.0000, 0.0701,  ..., 0.0000, 0.2057, 0.0000],\n",
       "          [0.4756, 0.0000, 0.3039,  ..., 0.0000, 0.2601, 0.0402],\n",
       "          [0.1227, 0.0000, 0.6663,  ..., 0.4138, 0.2358, 0.2359],\n",
       "          ...,\n",
       "          [0.0791, 0.0000, 0.0187,  ..., 0.1774, 0.3614, 0.0000],\n",
       "          [0.1651, 0.0000, 0.0000,  ..., 0.2701, 0.4265, 0.0000],\n",
       "          [0.1637, 0.0000, 0.1370,  ..., 0.1219, 0.1614, 0.0000]]),\n",
       "  tensor([[0.3160, 0.0427, 0.0000,  ..., 0.0000, 0.1369, 0.0000],\n",
       "          [0.2201, 0.2300, 0.0000,  ..., 0.0000, 0.2120, 0.0000],\n",
       "          [0.3574, 0.0000, 0.0000,  ..., 0.0000, 0.2116, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0942, 0.1120, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0147, 0.1059, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0141, 0.0587, 0.0000]]),\n",
       "  tensor([[0.1736, 0.2697, 0.0000,  ..., 0.0000, 0.0828, 0.0455],\n",
       "          [0.2079, 0.0000, 0.3737,  ..., 0.0000, 0.1630, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.4222, 0.3266, 0.0384],\n",
       "          ...,\n",
       "          [0.0000, 0.2703, 0.0000,  ..., 0.0924, 0.1643, 0.0000],\n",
       "          [0.0000, 0.2714, 0.0000,  ..., 0.0984, 0.2797, 0.0000],\n",
       "          [0.0000, 0.2906, 0.0000,  ..., 0.1184, 0.1826, 0.0000]])),\n",
       " None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.prediction_step(model, {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": attention_mask,\n",
    "    \"score\": score\n",
    "    }\n",
    ", False)\n",
    "# TODO: fix the result of the forward method so it properly returns the result of a prediction step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}