{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reappraisal Training For Linguistic Distancing and Emotion Regulation\n",
    "\n",
    "\n",
    "## Setup\n",
    "```bash\n",
    "> pipenv shell  #Generates a new virtual environment based on Pipfile\n",
    "> pipenv install # Installs the packages in Pipfile.lock (Use --dev) to also install dev packages\n",
    "```\n",
    "## Included Datasets\n",
    "- LDHII \n",
    "- \n",
    "- Emobank\n",
    "**Sources**\n",
    "-  [Sentiment Analysis Text Classification Tutorial](https://www.youtube.com/watch?v=8N-nM3QW7O0)\n",
    "- [Using Catalyst for Training Organization](https://github.com/catalyst-team/catalyst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install wandb -qqq\n",
    "# import wandb\n",
    "# !wandb login\n",
    "\n",
    "## Sample code for tracking model training runs in wandb \n",
    "# see: https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Intro_to_Weights_%26_Biases.ipynb#scrollTo=-VE3MabfZAcx\n",
    "# import math\n",
    "# import random\n",
    "\n",
    "# # 1️⃣ Start a new run, tracking config metadata\n",
    "# wandb.init(project=\"test-drive\", config={\n",
    "#     \"learning_rate\": 0.02,\n",
    "#     \"dropout\": 0.2,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"CIFAR-100\",\n",
    "# })\n",
    "# config = wandb.config\n",
    "\n",
    "# # Simulating a training or evaluation loop\n",
    "# for x in range(50):\n",
    "#     acc = math.log(1 + x + random.random() * config.learning_rate) + random.random()\n",
    "#     loss = 10 - math.log(1 + x + random.random() + config.learning_rate * x) + random.random()\n",
    "#     # 2️⃣ Log metrics from your script to W&B\n",
    "#     wandb.log({\"acc\":acc, \"loss\":loss})\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add Open in Colab Button\n",
    "# TODO: Write scripts for running as CLI in pipfile\n",
    "# TODO: hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "# !pipenv install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, running on CPU\n"
     ]
    }
   ],
   "source": [
    "from datasets import ReadInstruction\n",
    "\n",
    "# Enable GPU usage, if we can.\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Enabling GPU usage\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    IS_GPU = True\n",
    "else:\n",
    "    print(\"No GPU available, running on CPU\")\n",
    "    device = torch.device(\"cpu\") # Note: macOS incompatible with NVIDIA GPUs\n",
    "    IS_GPU = False\n",
    "    \n",
    "# Constants and environment setup\n",
    "# TODO: Set up env files for dev and \"prod\"\n",
    "#Casing can matter for sentiment analysis (\"bad\" vs. \"BAD\")\n",
    "PRETRAINED_MODEL_NAME = 'distilbert-base-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDH Dataset Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.LDHData import LDHData\n",
    "\n",
    "data = LDHData()\n",
    "ldh_train, ldh_eval = data.get_spatiotemp_data().values()\n",
    "# Split LDH Data into a training dataset and a validation dataset.\n",
    "train_ds = ldh_train.train_test_split(test_size=0.15) # shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB Dataset Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmoBank Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743460fdbf504d7ead3435b292cd1ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=716.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c80266da784646905b6624419273c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=127.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
       " 'response': Value(dtype='string', id=None),\n",
       " 'score': Value(dtype='float32', id=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "from datasets import Features, Sequence, Value\n",
    "# Tokenize the datasets.\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "# Add score to the model inputs so we can calculate loss.\n",
    "tokenizer.model_input_names.append(\"score\")\n",
    "encoded_ds= train_ds.map(\n",
    "    lambda batch: tokenizer(\n",
    "        batch['response'],\n",
    "        add_special_tokens=True,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True), \n",
    "    batched=True, batch_size=16, features=Features({\n",
    "        'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
    "        'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
    "        'response': Value(dtype='string', id=None),\n",
    "        'score': Value(dtype='float32', id=None)\n",
    "    }))\n",
    "\n",
    "\n",
    "# Reformat the dataset to PyTorch tensors.\n",
    "encoded_ds.set_format(type='torch', columns=['attention_mask', 'input_ids', 'score'])\n",
    "\n",
    "# {'attention_mask': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
    "#  'input_ids': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
    "#  'response': Value(dtype='string', id=None),\n",
    "#  'score': Value(dtype='float64', id=None)}\n",
    "\n",
    "encoded_ds['train'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['attention_mask', 'input_ids', 'score'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielpham/Library/Caches/pypoetry/virtualenvs/reapp-p6yGuJKm-py3.8/lib/python3.8/site-packages/datasets/arrow_dataset.py:851: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.tensor(x, **format_kwargs)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DistilBertModel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.ReappModel import ReappModel\n",
    "\n",
    "# Create the training model.\n",
    "# TODO: Suppress initialization errors.\n",
    "model = ReappModel(DistilBertModel, PRETRAINED_MODEL_NAME)\n",
    "\n",
    "num_train_epochs = 3 if IS_GPU else 1\n",
    "\n",
    "# Define the parameters under which the model will be trained.\n",
    "# By default, uses an AdamW optimizer w/ linear warmup.\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    ")\n",
    "encoded_train = encoded_ds['train']\n",
    "encoded_test  = encoded_ds['test']\n",
    "\n",
    "print(encoded_train[0].keys())\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,                  \n",
    "    train_dataset=encoded_train,      \n",
    "    eval_dataset=encoded_test         \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16]) torch.Size([16])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "eval_dataset must implement __len__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-01b3a84c311d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m trainer.evaluate(model, {\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/reapp-p6yGuJKm-py3.8/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   1435\u001b[0m         \"\"\"\n\u001b[1;32m   1436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_dataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eval_dataset must implement __len__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m         \u001b[0meval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_eval_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: eval_dataset must implement __len__"
     ]
    }
   ],
   "source": [
    "encoded_train_step = encoded_train.select(range(16))\n",
    "input_ids = encoded_train_step['input_ids']\n",
    "attention_mask = encoded_train_step['attention_mask']\n",
    "score = encoded_train_step['score'],\n",
    "\n",
    "trainer.training_step(model, {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": attention_mask,\n",
    "    \"score\": score\n",
    "    }\n",
    ")\n",
    "\n",
    "trainer.evaluate(model, {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": attention_mask,\n",
    "    \"score\": score\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation: Parse the TrainOutput Object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
