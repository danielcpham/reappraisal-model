{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reappraisal Training For Linguistic Distancing and Emotion Regulation\n",
    "\n",
    "\n",
    "## Setup\n",
    "```bash\n",
    "> pipenv shell  #Generates a new virtual environment based on Pipfile\n",
    "> pipenv install # Installs the packages in Pipfile.lock (Use --dev) to also install dev packages\n",
    "```\n",
    "## Included Datasets\n",
    "- LDHII \n",
    "- \n",
    "- Emobank\n",
    "**Sources**\n",
    "-  [Sentiment Analysis Text Classification Tutorial](https://www.youtube.com/watch?v=8N-nM3QW7O0)\n",
    "- [Using Catalyst for Training Organization](https://github.com/catalyst-team/catalyst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Add Open in Colab Button\n",
    "# TODO: Write scripts for running as CLI in pipfile\n",
    "# TODO: hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "# !pipenv install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, running on CPU\n"
     ]
    }
   ],
   "source": [
    "from datasets import ReadInstruction\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "# Enable GPU usage, if we can.\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Enabling GPU usage\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    IS_GPU = True\n",
    "else:\n",
    "    print(\"No GPU available, running on CPU\")\n",
    "    device = torch.device(\"cpu\") # Note: macOS incompatible with NVIDIA GPUs\n",
    "    IS_GPU = False\n",
    "    \n",
    "# Constants and environment setup\n",
    "# TODO: Set up env files for dev and \"prod\"\n",
    "#Casing can matter for sentiment analysis (\"bad\" vs. \"BAD\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "\n",
    "tokenize_func = lambda batch: tokenizer(\n",
    "    batch['response'],\n",
    "    add_special_tokens=True,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True)\n",
    "\n",
    "PRETRAINED_MODEL_NAME = 'distilbert-base-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDH Dataset Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.LDHData import LDHData\n",
    "\n",
    "data = LDHData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB Dataset Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmoBank Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c238de864f4f148438da48feb4f659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=842.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4f36abc5874af0b1bcc3d85b8f555b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=842.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa18e5880f641309ffb34b66243f224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1436.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb125ed7b5e432dafcd6495f2b813bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1436.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train': DatasetDict({\n",
       "     far: Dataset({\n",
       "         features: ['attention_mask', 'input_ids', 'response', 'score'],\n",
       "         num_rows: 13470\n",
       "     })\n",
       "     obj: Dataset({\n",
       "         features: ['attention_mask', 'input_ids', 'response', 'score'],\n",
       "         num_rows: 13470\n",
       "     })\n",
       " }),\n",
       " 'eval': DatasetDict({\n",
       "     far: Dataset({\n",
       "         features: ['__index_level_0__', 'addcode', 'attention_mask', 'input_ids', 'level_0', 'response'],\n",
       "         num_rows: 22972\n",
       "     })\n",
       "     obj: Dataset({\n",
       "         features: ['__index_level_0__', 'addcode', 'attention_mask', 'input_ids', 'level_0', 'response'],\n",
       "         num_rows: 22972\n",
       "     })\n",
       " })}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "from datasets import Features, Sequence, Value, DatasetDict\n",
    "# Tokenize the datasets.\n",
    "# Add score to the model inputs so we can calculate loss.\n",
    "\n",
    "# encoded_ds = data.encode(tokenizer, train_ds)\n",
    "\n",
    "# encoded_ds['train'].features\n",
    "# data.set_tokenizer(tokenizer)\n",
    "# train_ds = data.get_train_far_data()\n",
    "\n",
    "encoded_ds = data.encode_datasets(tokenizer, batched=True, batch_size=16)\n",
    "encoded_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22972\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DistilBertModel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.ReappModel import ReappModel\n",
    "\n",
    "# Create the training model.\n",
    "# TODO: Suppress initialization errors.\n",
    "model = ReappModel(DistilBertModel, PRETRAINED_MODEL_NAME)\n",
    "\n",
    "num_train_epochs = 3 if IS_GPU else 1\n",
    "\n",
    "# Define the parameters under which the model will be trained.\n",
    "# By default, uses an AdamW optimizer w/ linear warmup.\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    ")\n",
    "encoded_train = encoded_ds['train']['far']\n",
    "encoded_eval  = encoded_ds['eval']['far']\n",
    "\n",
    "print(len(encoded_eval))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,                  \n",
    "    train_dataset=encoded_train,      \n",
    "    eval_dataset=encoded_eval         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16]) torch.Size([16])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "prediction_step() missing 1 required positional argument: 'prediction_loss_only'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-6371c7a5247e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m trainer.prediction_step(model, {\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: prediction_step() missing 1 required positional argument: 'prediction_loss_only'"
     ]
    }
   ],
   "source": [
    "encoded_train_step = encoded_train.select(range(16))\n",
    "input_ids = encoded_train_step['input_ids']\n",
    "attention_mask = encoded_train_step['attention_mask']\n",
    "score = encoded_train_step['score'],\n",
    "\n",
    "trainer.training_step(model, {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": attention_mask,\n",
    "    \"score\": score\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation: Parse the TrainOutput Object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16]) torch.Size([16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " (tensor(1.2515e+09),\n",
       "  tensor([[[0.2974, 0.0321, 0.0000,  ..., 0.0000, 0.1631, 0.0018],\n",
       "           [0.0479, 0.0141, 0.3758,  ..., 0.0000, 0.3087, 0.0000],\n",
       "           [0.1139, 0.0000, 0.1657,  ..., 0.0000, 0.2711, 0.0999],\n",
       "           ...,\n",
       "           [0.1065, 0.0070, 0.0000,  ..., 0.0000, 0.3119, 0.0000],\n",
       "           [0.2112, 0.0000, 0.0000,  ..., 0.0898, 0.3542, 0.0000],\n",
       "           [0.1867, 0.0075, 0.0000,  ..., 0.0000, 0.2876, 0.0000]],\n",
       "  \n",
       "          [[0.2513, 0.0061, 0.0000,  ..., 0.0000, 0.2053, 0.2262],\n",
       "           [0.1464, 0.0000, 0.0622,  ..., 0.0000, 0.5484, 0.0700],\n",
       "           [0.0000, 0.0000, 0.3078,  ..., 0.0834, 0.0246, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.1892, 0.3698, 0.0000],\n",
       "           [0.0000, 0.0129, 0.0000,  ..., 0.0833, 0.2472, 0.0000],\n",
       "           [0.0154, 0.0000, 0.0000,  ..., 0.0366, 0.3223, 0.0000]],\n",
       "  \n",
       "          [[0.0723, 0.0000, 0.0222,  ..., 0.0000, 0.2573, 0.1352],\n",
       "           [0.0000, 0.0000, 0.1659,  ..., 0.1130, 0.4028, 0.0000],\n",
       "           [0.0000, 0.0000, 0.2057,  ..., 0.4677, 0.3653, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0394,  ..., 0.0311, 0.2103, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.1882, 0.2852, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.1206, 0.1270, 0.0000]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[0.2306, 0.0000, 0.1843,  ..., 0.0000, 0.2900, 0.0000],\n",
       "           [0.3883, 0.0000, 0.2838,  ..., 0.0000, 0.2289, 0.0342],\n",
       "           [0.0542, 0.0000, 0.6822,  ..., 0.3159, 0.2842, 0.0562],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.1651,  ..., 0.2428, 0.2980, 0.0000],\n",
       "           [0.0557, 0.0000, 0.0725,  ..., 0.2008, 0.3519, 0.0000],\n",
       "           [0.0698, 0.0000, 0.0331,  ..., 0.1318, 0.2927, 0.0000]],\n",
       "  \n",
       "          [[0.2924, 0.0590, 0.0360,  ..., 0.0000, 0.1718, 0.0579],\n",
       "           [0.0000, 0.1834, 0.0000,  ..., 0.0000, 0.2360, 0.0000],\n",
       "           [0.2819, 0.0337, 0.0000,  ..., 0.0000, 0.3190, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.1409, 0.1542, 0.0000],\n",
       "           [0.0339, 0.0000, 0.0000,  ..., 0.1330, 0.1844, 0.0000],\n",
       "           [0.0592, 0.0000, 0.0000,  ..., 0.0000, 0.1101, 0.0000]],\n",
       "  \n",
       "          [[0.1986, 0.2154, 0.0000,  ..., 0.0000, 0.1142, 0.0301],\n",
       "           [0.1708, 0.0000, 0.3645,  ..., 0.0000, 0.0956, 0.0000],\n",
       "           [0.0361, 0.0716, 0.0000,  ..., 0.4551, 0.2914, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.4010, 0.0000,  ..., 0.2034, 0.1995, 0.0000],\n",
       "           [0.0000, 0.2527, 0.0000,  ..., 0.1158, 0.1933, 0.0000],\n",
       "           [0.0000, 0.2218, 0.0000,  ..., 0.1861, 0.2034, 0.0000]]])),\n",
       " None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.prediction_step(model, {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": attention_mask,\n",
    "    \"score\": score\n",
    "    }\n",
    ", False)\n",
    "# TODO: fix the result of the forward method so it properly returns the result of a prediction step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
