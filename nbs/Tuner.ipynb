{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tune \n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as lit\n",
    "from ray.tune.integration.pytorch_lightning import TuneReportCallback\n",
    "from ray import tune\n",
    "\n",
    "from reappraisalmodel.lightningreapp import LightningReapp\n",
    "\n",
    "callback_tuner = TuneReportCallback({\n",
    "    \"loss\": \"val_loss\",\n",
    "    #\"mean_accuracy\": \"val_accuracy\"\n",
    "    },\n",
    "    on=\"validation_end\")\n",
    "### TUNING HYPERPARAMETERS\n",
    "def train_tune(config, epochs=10):\n",
    "    gpus = 1 if torch.cuda.is_available() else None\n",
    "    model = LightningReapp(config)\n",
    "    trainer = lit.Trainer(\n",
    "        num_folds=3,\n",
    "        fast_dev_run=1,\n",
    "        max_epochs=epochs,\n",
    "        gpus=gpus,\n",
    "        progress_bar_refresh_rate=30,\n",
    "        callbacks=[callback_tuner])\n",
    "    trainer.fit(model, ldhdata)\n",
    "\n",
    "default_config = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"hidden_layer_size\": 50,\n",
    "}\n",
    "\n",
    "def run_tune(tune_config=default_config, num_samples=2):\n",
    "    tune.run(train_tune, config=tune_config, num_samples=num_samples)\n",
    "\n",
    "\n",
    "# https://medium.com/distributed-computing-with-ray/scaling-up-pytorch-lightning-hyperparameter-tuning-with-ray-tune-4bd9e1ff9929\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-17 16:33:56,448\tINFO services.py:1172 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2021-02-17 16:33:58,464\tWARNING function_runner.py:540 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n"
     ]
    },
    {
     "data": {
      "text/html": "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/4.15 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/danielpham/ray_results/train_tune_2021-02-17_16-33-58<br>Number of trials: 1/2 (1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name            </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">        lr</th></tr>\n</thead>\n<tbody>\n<tr><td>train_tune_39c99_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.00245444</td></tr>\n</tbody>\n</table><br><br>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m 2021-02-17 16:34:00,678\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 315, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m     return self._trainable_func(self.config, self._status_reporter,\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 576, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m   File \"<ipython-input-8-37354b7d4903>\", line 20, in train_tune\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m   File \"/Users/danielpham/Google Drive/ldh/nbs/reappraisalmodel/lightningreapp.py\", line 18, in __init__\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m     self.hidden_layer_size = config['hidden_layer_size']\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m KeyError: 'hidden_layer_size'\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 315, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m     return self._trainable_func(self.config, self._status_reporter,\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 576, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m   File \"<ipython-input-8-37354b7d4903>\", line 20, in train_tune\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m   File \"/Users/danielpham/Google Drive/ldh/nbs/reappraisalmodel/lightningreapp.py\", line 18, in __init__\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m     self.hidden_layer_size = config['hidden_layer_size']\n",
      "\u001b[2m\u001b[36m(pid=11865)\u001b[0m KeyError: 'hidden_layer_size'\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m 2021-02-17 16:34:00,677\tERROR function_runner.py:254 -- Runner Thread raised error.\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 315, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m     return self._trainable_func(self.config, self._status_reporter,\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 576, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m   File \"<ipython-input-8-37354b7d4903>\", line 20, in train_tune\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m   File \"/Users/danielpham/Google Drive/ldh/nbs/reappraisalmodel/lightningreapp.py\", line 18, in __init__\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m     self.hidden_layer_size = config['hidden_layer_size']\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m KeyError: 'hidden_layer_size'\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m Exception in thread Thread-2:\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m     self.run()\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 267, in run\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m     raise e\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m     self._entrypoint()\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 315, in entrypoint\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m     return self._trainable_func(self.config, self._status_reporter,\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m   File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 576, in _trainable_func\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m     output = fn()\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m   File \"<ipython-input-8-37354b7d4903>\", line 20, in train_tune\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m   File \"/Users/danielpham/Google Drive/ldh/nbs/reappraisalmodel/lightningreapp.py\", line 18, in __init__\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m     self.hidden_layer_size = config['hidden_layer_size']\n",
      "\u001b[2m\u001b[36m(pid=11861)\u001b[0m KeyError: 'hidden_layer_size'\n",
      "2021-02-17 16:34:00,889\tERROR trial_runner.py:616 -- Trial train_tune_39c99_00001: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 586, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 609, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 47, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/worker.py\", line 1456, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=11865, ip=192.168.50.84)\n",
      "  File \"python/ray/_raylet.pyx\", line 480, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 432, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/trainable.py\", line 167, in train_buffered\n",
      "    result = self.train()\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/trainable.py\", line 226, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 512, in _report_thread_runner_error\n",
      "    raise TuneError(\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=11865, ip=192.168.50.84)\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 315, in entrypoint\n",
      "    return self._trainable_func(self.config, self._status_reporter,\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 576, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-8-37354b7d4903>\", line 20, in train_tune\n",
      "  File \"/Users/danielpham/Google Drive/ldh/nbs/reappraisalmodel/lightningreapp.py\", line 18, in __init__\n",
      "    self.hidden_layer_size = config['hidden_layer_size']\n",
      "KeyError: 'hidden_layer_size'\n",
      "2021-02-17 16:34:00,899\tERROR trial_runner.py:616 -- Trial train_tune_39c99_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 586, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 609, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 47, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/worker.py\", line 1456, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(TuneError): \u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=11861, ip=192.168.50.84)\n",
      "  File \"python/ray/_raylet.pyx\", line 480, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 432, in ray._raylet.execute_task.function_executor\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/trainable.py\", line 167, in train_buffered\n",
      "    result = self.train()\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/trainable.py\", line 226, in train\n",
      "    result = self.step()\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 366, in step\n",
      "    self._report_thread_runner_error(block=True)\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 512, in _report_thread_runner_error\n",
      "    raise TuneError(\n",
      "ray.tune.error.TuneError: Trial raised an exception. Traceback:\n",
      "\u001b[36mray::ImplicitFunc.train_buffered()\u001b[39m (pid=11861, ip=192.168.50.84)\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 248, in run\n",
      "    self._entrypoint()\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 315, in entrypoint\n",
      "    return self._trainable_func(self.config, self._status_reporter,\n",
      "  File \"/Users/danielpham/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/function_runner.py\", line 576, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"<ipython-input-8-37354b7d4903>\", line 20, in train_tune\n",
      "  File \"/Users/danielpham/Google Drive/ldh/nbs/reappraisalmodel/lightningreapp.py\", line 18, in __init__\n",
      "    self.hidden_layer_size = config['hidden_layer_size']\n",
      "KeyError: 'hidden_layer_size'\n",
      "Result for train_tune_39c99_00001:\n",
      "  {}\n",
      "  \n",
      "Result for train_tune_39c99_00000:\n",
      "  {}\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.15 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/danielpham/ray_results/train_tune_2021-02-17_16-33-58<br>Number of trials: 2/2 (2 ERROR)<br><table>\n<thead>\n<tr><th>Trial name            </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">        lr</th></tr>\n</thead>\n<tbody>\n<tr><td>train_tune_39c99_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.00245444</td></tr>\n<tr><td>train_tune_39c99_00001</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.00698284</td></tr>\n</tbody>\n</table><br>Number of errored trials: 2<br><table>\n<thead>\n<tr><th>Trial name            </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                      </th></tr>\n</thead>\n<tbody>\n<tr><td>train_tune_39c99_00000</td><td style=\"text-align: right;\">           1</td><td>/Users/danielpham/ray_results/train_tune_2021-02-17_16-33-58/train_tune_39c99_00000_0_lr=0.0024544_2021-02-17_16-33-58/error.txt</td></tr>\n<tr><td>train_tune_39c99_00001</td><td style=\"text-align: right;\">           1</td><td>/Users/danielpham/ray_results/train_tune_2021-02-17_16-33-58/train_tune_39c99_00001_1_lr=0.0069828_2021-02-17_16-33-58/error.txt</td></tr>\n</tbody>\n</table><br>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_tune_39c99_00000, train_tune_39c99_00001])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1ad1bc5818f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-1ad1bc5818f6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-37354b7d4903>\u001b[0m in \u001b[0;36mrun_tune\u001b[0;34m(tune_config, num_samples)\u001b[0m\n\u001b[1;32m     32\u001b[0m }\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_tune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtune_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.7/lib/python3.8/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [train_tune_39c99_00000, train_tune_39c99_00001])"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(run_tune())\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Tuner.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script; \n",
    "notebook2script(\"Tuner.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
