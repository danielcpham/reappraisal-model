{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reappraisal Training on PyTorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "- When running on Google Colab, mount Google Drive to access scripts.\n",
    "- `cd` into the project root and install dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd {root_dir}\n",
    "\n",
    "%pip install pytorch-lightning \"ray[tune]\" wandb transformers datasets nltk \n",
    "%pip install nbdev \n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "ROOT_DIR = '/home/ec2-user/SageMaker/reappraisal-model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define constants\n",
    "STRAT = 'obj'\n",
    "BATCH_SIZE = 16 if not torch.cuda.is_available() else 16\n",
    "TEST_BATCH_SIZE = 64\n",
    "NUM_FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LDH Data\n",
    "\n",
    "Contains the following:\n",
    "\n",
    "- LDHI\n",
    "- LDHII\n",
    "- LDHIII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of reappraisalmodel.ldhdata failed: Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 410, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 302, in update_class\n",
      "    if update_generic(old_obj, new_obj): continue\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 347, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 266, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: prepare_data() requires a code object with 1 free vars, not 0\n",
      "]\n",
      "Loading cached processed dataset at /home/ec2-user/SageMaker/reappraisal-model/output/training/obj/cache-737adc3f1ed4b28c.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded from disk.\n",
      "Encoding Train Data:\n",
      "Evaluation data loaded from disk.\n",
      "Encoding Test Data:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560f9ec3044742b78d98824e91167ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32109.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from reappraisalmodel.ldhdata import LDHDataModule\n",
    "ldhdata = LDHDataModule(data_dir=ROOT_DIR, batch_size=BATCH_SIZE, strat=STRAT, kfolds=NUM_FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run K-Fold Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (trainers.py, line 56)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3331\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-af57950142cf>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from reappraisalmodel.trainers import kfold_train\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/ec2-user/SageMaker/reappraisal-model/reappraisalmodel/trainers.py\"\u001b[0;36m, line \u001b[0;32m56\u001b[0m\n\u001b[0;31m    filename=f'{str(today)}-{strat}' + '-{epoch:.2d}-{val_loss:.02f}',\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from reappraisalmodel.trainers import kfold_train\n",
    "\n",
    "results = kfold_train(NUM_FOLDS, ldhdata, strat=STRAT, max_epochs=20, fast_dev_run=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from reappraisalmodel.trainers import run_tune\n",
    "run_tune(ldhdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained(pretrained_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# Returns a BatchEncoding of the text.\n",
    "tokenized = tokenizer(text = [\"This is the first test sentence!\", \"This is the second, better test sentence.\"], \n",
    "    padding='max_length', max_length=150)\n",
    "\n",
    "for idx, sent in enumerate(tokenized.input_ids):\n",
    "    print(f\"Sentence            {idx}: {tokenizer.convert_ids_to_tokens(sent)}\")\n",
    "    print(f\"Tokenized Attention {idx}: {tokenized[idx].attention_mask}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import torch\n",
    "import pytorch_lightning as lit\n",
    "from reappraisalmodel.lightningreapp import LightningReapp\n",
    "\n",
    "default_config = default_config = {\n",
    "    'lr': 1e-3,\n",
    "    'hidden_layer_size': 50\n",
    "}\n",
    "\n",
    "model = LightningReapp(default_config)\n",
    "\n",
    "trainer = lit.Trainer(\n",
    "    gpus = 1 if torch.cuda.is_available() else None,\n",
    "    gradient_clip_val=1.0,\n",
    "    progress_bar_refresh_rate=30,\n",
    "    max_epochs=10,\n",
    "    fast_dev_run=2,\n",
    "    terminate_on_nan=True)\n",
    "\n",
    "model = LightningReapp(default_config)\n",
    "\n",
    "trainer.fit(model, ldhdata.train_dataloader(), ldhdata.val_dataloader())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightningReapp.load_from_checkpoint(\n",
    "    '/Users/danielpham/Google Drive/ldh/lightning_logs_obj_0223/version_2/checkpoints/epoch=1-step=337.ckpt', map_location='cpu')\n",
    "\n",
    "model.eval()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pytorch_lightning import Trainer \n",
    "\n",
    "model.eval()\n",
    "trainer = Trainer(\n",
    "    gradient_clip_val=1.0,\n",
    "    progress_bar_refresh_rate=30,\n",
    "    terminate_on_nan=True)\n",
    "\n",
    "test_dataloader = ldhdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for result in results:\n",
    "    print(len(result['predict']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./output_reapp.pkl', 'rb+') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pickle\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = 'ldhdata'\n",
    "file = 'Master_Final_TrainingData.csv'\n",
    "\n",
    "s3client = boto3.client('s3')\n",
    "\n",
    "response = s3client.get_object(Bucket=bucket, Key=file)\n",
    "\n",
    "import codecs \n",
    "import csv\n",
    "\n",
    "train = csv.DictReader(codecs.getreader(\"utf-8\")(response[\"Body\"])) # returns an ordered dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_lightning.metrics.functional import r2score, explained_variance\n",
    "\n",
    "expected = torch.rand(16)\n",
    "observed = torch.rand(16)\n",
    "\n",
    "r2score(expected, observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%nbdev_build_lib` not found.\n"
     ]
    }
   ],
   "source": [
    "%nbdev_build_lib --fname 'Trainers.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
