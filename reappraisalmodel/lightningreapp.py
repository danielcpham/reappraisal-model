# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/LightningReapp.ipynb (unless otherwise specified).

__all__ = ['LightningReapp']

# Cell
import pandas as pd
import pytorch_lightning as lit
import torch
from torch import nn, optim
from torch.nn import functional as F
from transformers import AutoModel

class LightningReapp(lit.LightningModule):
    def __init__(self, config, pretrained_model=None):
        super().__init__()

        self.lr = config['lr']
        self.hidden_layer_size = config['hidden_layer_size']
        self.save_hyperparameters()

        pretrained_model = "distilbert-base-uncased-finetuned-sst-2-english" if pretrained_model is None else pretrained_model

        self.model = AutoModel.from_pretrained(pretrained_model)

        self.avg = nn.AvgPool1d(150)

        self.classifier = nn.Sequential(
            nn.Linear(768, 768),
            nn.Linear(768, self.hidden_layer_size),
            nn.ReLU(),
            nn.Linear(self.hidden_layer_size, 10),
            nn.ReLU(),
        )

        # define metrics
        self.train_loss = lit.metrics.MeanSquaredError()
        self.val_loss = lit.metrics.MeanSquaredError()



    def forward(self, input_ids, attention_mask):
        output = self.model(input_ids, attention_mask)
        last_hidden_state = output.last_hidden_state
        avg = self.avg(last_hidden_state.transpose(2, 1))
        out = self.classifier(avg.transpose(2, 1)).squeeze()
        return out

    def configure_optimizers(self):
        optimizer = optim.Adam(self.parameters(), lr=self.lr)
        return optimizer

    def training_step(self, batch, batch_idx):
        # destructure batch
        input_ids = batch["input_ids"]
        attention_mask = batch["attention_mask"]
        score = batch["score"]
        # Compute the loss
        output = self(input_ids, attention_mask)
        loss = self.train_loss(output.sum(dim=1), score)
        self.log("train_loss", loss)
        return {"loss": loss}

    def training_epoch_end(self, outputs):
        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()
        self.log("train_loss", avg_loss)

    # VALIDATION LOOP
    def validation_step(self, batch, batch_idx):
        input_ids = batch["input_ids"]
        attention_mask = batch["attention_mask"]
        score = batch["score"]
        output = self(input_ids, attention_mask)
        loss = self.val_loss(output.sum(dim=1), score)
        self.log("val_loss", loss)
        return {"loss": loss}

    def validation_epoch_end(self, outputs):
        print(outputs)
        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()
        self.log("val_loss", avg_loss)

    # TESTING LOOP
    def test_step(self, batch, batch_idx):
        input_ids = batch["input_ids"]
        attention_mask = batch["attention_mask"]
        output = self(input_ids, attention_mask)
        # Eval step
        return {
            "predict": pd.DataFrame(
                {
                    "addcode": batch['addcode'],
                    "daycode": batch['daycode'],
                    "condition": batch['Condition'],
                    "response": batch["response"],
                    "output": output.sum(dim=1)
                    }
            )
        }