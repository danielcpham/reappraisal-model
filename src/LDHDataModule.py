from collections import namedtuple
from types import MethodType
from typing import Generator, List, Tuple

import numpy as np
import pytorch_lightning as lit
from datasets import Dataset, DatasetDict
from sklearn.model_selection import GroupKFold
from torch.utils.data import RandomSampler, DataLoader
from torch.utils.data.dataset import Subset
from transformers import AutoTokenizer

import pdb

from .LDHData import LDHData

DEFAULT_TOKENIZER = AutoTokenizer.from_pretrained(
            "distilbert-base-uncased-finetuned-sst-2-english", use_fast=True)

class LDHDataModule(lit.LightningDataModule):
    def __init__(self, batch_size=16, tokenizer=DEFAULT_TOKENIZER, strat='obj', kfolds=5, force_reload=False):
        super().__init__()
        self.strat = strat
        self.batch_size = batch_size
        self.tokenizer = tokenizer
        self.kfolds = kfolds
        self.current_split = 0

        data = LDHData(self.tokenizer) 
        
        self.train_data = self.load_training_data(data, force_reload)
        self.indices = self.assign_groups()
        self.splits = self.generate_splits(self.indices)
        self.eval_data = self.load_eval_data(data, force_reload)

    def load_training_data(self, data:LDHData, force_reload):
        data.load_training_data(force_reload)
        train_data: Dataset = data.train_dataset[self.strat] 
        print("Encoding Train Data:")
        encoded_ds = train_data.map(
            lambda ds: self.tokenizer(
                ds["response"],
                add_special_tokens=True,
                padding="max_length",
                max_length=150,
            )
        )
        encoded_ds.set_format(
            type="torch", columns=["input_ids", "attention_mask", "score"],
        )
        return encoded_ds

    def load_eval_data(self, data:LDHData, force_reload):
        data.load_eval_data(force_reload)
        eval_data: Dataset = data.eval_dataset[self.strat]
        print("Encoding Test Data:")
        encoded_ds = eval_data.map(
            lambda ds: self.tokenizer(
                ds["response"],
                add_special_tokens=True,
                padding="max_length",                    
                max_length=150,
            )
        )
        # Need to include addcode here as well
        encoded_ds.set_format(
            type="torch", columns=["input_ids", "attention_mask"], output_all_columns=True
        )
        return encoded_ds
    
    def assign_groups(self):
        """ Assign each datapoint to a group for later kfold validation

        Returns:
            [type]: [description]
        """
        indices = np.arange(len(self.train_data))
        indices = indices % self.kfolds
        np.random.shuffle(indices)
        return indices

    def generate_splits(self, indices):            
        cv = GroupKFold(self.kfolds)
        splits = list(cv.split(self.train_data, groups=indices))
        return splits

    def get_train_dataloader(self, split: int):
        train_idx = self.splits[split][0].tolist() # retrieve the split generated by GroupKFold
        data = Subset(self.train_data, train_idx)
        return DataLoader(data, batch_size=self.batch_size)
    
    def get_val_dataloader(self, split: int):
        val_idx = self.splits[split][1].tolist() # retrieve the split generated by GroupKFold
        data = Subset(self.train_data, val_idx)
        return DataLoader(data, batch_size=self.batch_size)

    def train_dataloader(self):
        return self.get_train_dataloader(self.current_split)

    def val_dataloader(self):
        return self.get_val_dataloader(self.current_split)

    def test_dataloader(self):
        return DataLoader(self.eval_data, batch_size=self.batch_size)
