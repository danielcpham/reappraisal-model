{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reappraisal Training For Linguistic Distancing and Emotion Regulation\n",
    "\n",
    "\n",
    "## Setup\n",
    "```bash\n",
    "> pipenv shell  #Generates a new virtual environment based on Pipfile\n",
    "> pipenv install # Installs the packages in Pipfile.lock (Use --dev) to also install dev packages\n",
    "```\n",
    "## Included Datasets\n",
    "- LDHII \n",
    "- \n",
    "- Emobank\n",
    "**Sources**\n",
    "-  [Sentiment Analysis Text Classification Tutorial](https://www.youtube.com/watch?v=8N-nM3QW7O0)\n",
    "- [Using Catalyst for Training Organization](https://github.com/catalyst-team/catalyst)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install wandb -qqq\n",
    "# import wandb\n",
    "# !wandb login\n",
    "\n",
    "## Sample code for tracking model training runs in wandb \n",
    "# see: https://colab.research.google.com/github/wandb/examples/blob/master/colabs/intro/Intro_to_Weights_%26_Biases.ipynb#scrollTo=-VE3MabfZAcx\n",
    "# import math\n",
    "# import random\n",
    "\n",
    "# # 1️⃣ Start a new run, tracking config metadata\n",
    "# wandb.init(project=\"test-drive\", config={\n",
    "#     \"learning_rate\": 0.02,\n",
    "#     \"dropout\": 0.2,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"CIFAR-100\",\n",
    "# })\n",
    "# config = wandb.config\n",
    "\n",
    "# # Simulating a training or evaluation loop\n",
    "# for x in range(50):\n",
    "#     acc = math.log(1 + x + random.random() * config.learning_rate) + random.random()\n",
    "#     loss = 10 - math.log(1 + x + random.random() + config.learning_rate * x) + random.random()\n",
    "#     # 2️⃣ Log metrics from your script to W&B\n",
    "#     wandb.log({\"acc\":acc, \"loss\":loss})\n",
    "\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Add Open in Colab Button\n",
    "# TODO: Write scripts for running as CLI in pipfile\n",
    "# TODO: hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, running on CPU\n"
     ]
    }
   ],
   "source": [
    "from datasets import ReadInstruction\n",
    "\n",
    "# Enable GPU usage, if we can.\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Enabling GPU usage\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    IS_GPU = True\n",
    "else:\n",
    "    print(\"No GPU available, running on CPU\")\n",
    "    device = torch.device(\"cpu\") # Note: macOS incompatible with NVIDIA GPUs\n",
    "    IS_GPU = False\n",
    "    \n",
    "# Constants and environment setup\n",
    "# TODO: Set up env files for dev and \"prod\"\n",
    "#Casing can matter for sentiment analysis (\"bad\" vs. \"BAD\")\n",
    "PRETRAINED_MODEL_NAME = 'distilbert-base-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDH Dataset Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'spatiotemp': Dataset({\n",
       "      features: ['response', 'spatiotemp'],\n",
       "      num_rows: 13472\n",
       "  }),\n",
       "  'obj': Dataset({\n",
       "      features: ['response', 'obj'],\n",
       "      num_rows: 13472\n",
       "  })},\n",
       " {'spatiotemp': Dataset({\n",
       "      features: ['addcode', 'subjID', 'condition', 'response'],\n",
       "      num_rows: 1638\n",
       "  }),\n",
       "  'obj': Dataset({\n",
       "      features: ['addcode', 'subjID', 'condition', 'response'],\n",
       "      num_rows: 1638\n",
       "  })})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from LDHData import LDHData\n",
    "\n",
    "data = LDHData()\n",
    "ldh_train = data.train_data\n",
    "ldh_eval = data.eval_data\n",
    "\n",
    "ldh_train, ldh_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(27, 2.6875),\n",
       " (15, 2.5),\n",
       " (18, 5.0),\n",
       " (21, 4.0),\n",
       " (18, 1.0),\n",
       " (15, 5.0),\n",
       " (10, 2.75),\n",
       " (23, 4.0),\n",
       " (19, 6.0),\n",
       " (12, 2.0),\n",
       " (24, 5.0),\n",
       " (21, 1.5),\n",
       " (21, 2.0),\n",
       " (14, 3.0),\n",
       " (8, 2.3333333333333335),\n",
       " (22, 3.785714285714286),\n",
       " (7, 1.6666666666666667),\n",
       " (13, 1.0),\n",
       " (10, 2.5),\n",
       " (10, 4.5),\n",
       " (17, 4.0),\n",
       " (14, 7.0),\n",
       " (10, 2.5),\n",
       " (16, 2.5),\n",
       " (7, 1.0),\n",
       " (21, 2.0),\n",
       " (17, 2.0),\n",
       " (6, 3.0),\n",
       " (13, 1.5),\n",
       " (40, 3.0),\n",
       " (6, 2.0),\n",
       " (28, 5.0),\n",
       " (17, 1.0),\n",
       " (10, 1.0),\n",
       " (19, 2.947368421052631),\n",
       " (18, 1.5),\n",
       " (9, 4.5),\n",
       " (14, 3.5),\n",
       " (8, 2.0),\n",
       " (16, 3.0),\n",
       " (15, 2.5),\n",
       " (16, 3.0),\n",
       " (14, 2.5),\n",
       " (10, 2.5),\n",
       " (14, 3.0),\n",
       " (17, 1.0),\n",
       " (25, 3.5),\n",
       " (10, 3.0),\n",
       " (18, 3.384615384615385),\n",
       " (60, 3.5),\n",
       " (46, 2.5),\n",
       " (23, 3.5),\n",
       " (28, 2.837837837837838),\n",
       " (17, 6.0),\n",
       " (14, 2.0),\n",
       " (8, 2.0),\n",
       " (8, 2.0),\n",
       " (16, 6.5),\n",
       " (6, 3.5),\n",
       " (10, 2.0),\n",
       " (13, 3.0),\n",
       " (11, 1.891891891891892),\n",
       " (16, 3.0),\n",
       " (24, 3.0),\n",
       " (13, 1.0),\n",
       " (6, 2.0),\n",
       " (8, 1.5),\n",
       " (42, 3.0),\n",
       " (20, 6.0),\n",
       " (19, 2.0),\n",
       " (21, 2.0),\n",
       " (26, 4.5),\n",
       " (5, 2.5),\n",
       " (5, 2.6666666666666665),\n",
       " (8, 1.0),\n",
       " (10, 4.0),\n",
       " (6, 2.0),\n",
       " (18, 2.648648648648649),\n",
       " (20, 2.875),\n",
       " (14, 2.5),\n",
       " (11, 3.0),\n",
       " (7, 5.0),\n",
       " (18, 2.48780487804878),\n",
       " (9, 4.0),\n",
       " (26, 3.0),\n",
       " (8, 4.0),\n",
       " (8, 3.0),\n",
       " (8, 2.790697674418605),\n",
       " (13, 4.0),\n",
       " (20, 2.5),\n",
       " (18, 1.0),\n",
       " (17, 4.0),\n",
       " (23, 3.0),\n",
       " (14, 4.0),\n",
       " (5, 2.413793103448276),\n",
       " (10, 2.461538461538462),\n",
       " (8, 3.185185185185185),\n",
       " (21, 7.0),\n",
       " (27, 4.023809523809524),\n",
       " (11, 1.0),\n",
       " (29, 5.5),\n",
       " (13, 2.5),\n",
       " (14, 2.0),\n",
       " (53, 6.0),\n",
       " (10, 3.0),\n",
       " (17, 1.0),\n",
       " (17, 3.0),\n",
       " (6, 3.0),\n",
       " (13, 2.0),\n",
       " (9, 1.0),\n",
       " (5, 1.0),\n",
       " (11, 1.0),\n",
       " (21, 1.0),\n",
       " (16, 3.5),\n",
       " (9, 4.0),\n",
       " (19, 1.0),\n",
       " (4, 1.0),\n",
       " (60, 2.709677419354839),\n",
       " (29, 5.0),\n",
       " (23, 5.0),\n",
       " (9, 1.0),\n",
       " (14, 4.071428571428571),\n",
       " (17, 3.0),\n",
       " (14, 6.0),\n",
       " (6, 1.0),\n",
       " (6, 5.0),\n",
       " (24, 5.0),\n",
       " (22, 4.0),\n",
       " (49, 3.37037037037037),\n",
       " (5, 1.0),\n",
       " (26, 4.0),\n",
       " (7, 1.0),\n",
       " (15, 6.0),\n",
       " (2, 2.105263157894737),\n",
       " (10, 2.0),\n",
       " (8, 1.0),\n",
       " (8, 3.0),\n",
       " (6, 2.307692307692307),\n",
       " (23, 2.810810810810811),\n",
       " (12, 2.5),\n",
       " (48, 2.6666666666666665),\n",
       " (15, 5.0),\n",
       " (37, 1.0),\n",
       " (6, 1.0),\n",
       " (10, 3.0),\n",
       " (14, 1.0),\n",
       " (7, 4.0),\n",
       " (9, 4.0),\n",
       " (9, 5.0),\n",
       " (24, 3.0),\n",
       " (8, 1.5),\n",
       " (22, 2.5),\n",
       " (9, 1.0),\n",
       " (14, 5.0),\n",
       " (24, 5.5),\n",
       " (8, 1.5),\n",
       " (18, 5.0),\n",
       " (12, 6.0),\n",
       " (15, 1.0),\n",
       " (14, 1.0),\n",
       " (15, 5.0),\n",
       " (21, 1.5),\n",
       " (25, 2.526315789473684),\n",
       " (10, 2.6666666666666665),\n",
       " (8, 1.0),\n",
       " (5, 2.0),\n",
       " (10, 2.0),\n",
       " (7, 6.0),\n",
       " (19, 4.0),\n",
       " (15, 3.0),\n",
       " (28, 6.0),\n",
       " (7, 1.0),\n",
       " (15, 2.0),\n",
       " (49, 7.0),\n",
       " (5, 1.0),\n",
       " (14, 2.5),\n",
       " (21, 2.0),\n",
       " (27, 4.0),\n",
       " (3, 2.178571428571428),\n",
       " (26, 3.571428571428572),\n",
       " (24, 3.642857142857143),\n",
       " (10, 2.0),\n",
       " (21, 3.0),\n",
       " (24, 1.5),\n",
       " (18, 2.5),\n",
       " (8, 2.75),\n",
       " (14, 2.5),\n",
       " (19, 1.0),\n",
       " (7, 1.0),\n",
       " (15, 2.5),\n",
       " (29, 3.71875),\n",
       " (19, 3.5),\n",
       " (7, 2.241379310344827),\n",
       " (7, 3.111111111111111),\n",
       " (4, 1.5),\n",
       " (15, 2.5),\n",
       " (13, 4.0),\n",
       " (6, 5.0),\n",
       " (25, 1.5),\n",
       " (14, 1.0),\n",
       " (5, 1.0),\n",
       " (6, 3.0),\n",
       " (13, 3.0),\n",
       " (6, 2.0),\n",
       " (17, 5.0),\n",
       " (8, 5.5),\n",
       " (14, 1.0),\n",
       " (45, 5.0),\n",
       " (17, 5.0),\n",
       " (19, 2.894736842105263),\n",
       " (10, 2.5),\n",
       " (38, 1.5),\n",
       " (16, 3.0),\n",
       " (18, 3.5),\n",
       " (8, 1.0),\n",
       " (36, 6.0),\n",
       " (17, 2.0),\n",
       " (7, 4.5),\n",
       " (14, 3.0),\n",
       " (15, 4.5),\n",
       " (5, 2.259259259259259),\n",
       " (11, 3.0),\n",
       " (26, 1.5),\n",
       " (26, 1.5),\n",
       " (16, 1.0),\n",
       " (8, 1.0),\n",
       " (47, 5.5),\n",
       " (14, 2.0),\n",
       " (9, 2.0),\n",
       " (17, 5.0),\n",
       " (12, 3.0),\n",
       " (5, 3.0),\n",
       " (6, 2.5),\n",
       " (9, 2.666666666666667),\n",
       " (27, 2.526315789473684),\n",
       " (36, 5.5),\n",
       " (7, 2.0),\n",
       " (5, 3.0),\n",
       " (13, 2.0),\n",
       " (13, 2.0),\n",
       " (9, 2.0),\n",
       " (7, 1.0),\n",
       " (16, 1.5),\n",
       " (8, 1.5),\n",
       " (5, 2.428571428571428),\n",
       " (6, 1.0),\n",
       " (7, 3.0),\n",
       " (27, 4.0),\n",
       " (10, 1.0),\n",
       " (18, 5.0),\n",
       " (12, 1.0),\n",
       " (19, 1.0),\n",
       " (18, 5.0),\n",
       " (15, 2.0),\n",
       " (5, 3.5),\n",
       " (32, 6.0),\n",
       " (22, 2.368421052631579),\n",
       " (9, 3.0),\n",
       " (28, 1.0),\n",
       " (10, 2.0),\n",
       " (18, 3.5),\n",
       " (20, 3.0),\n",
       " (27, 4.0),\n",
       " (11, 1.0),\n",
       " (16, 3.0),\n",
       " (20, 2.0),\n",
       " (24, 5.0),\n",
       " (21, 2.842105263157895),\n",
       " (13, 3.5),\n",
       " (8, 2.5),\n",
       " (12, 2.0),\n",
       " (18, 2.421052631578947),\n",
       " (12, 1.0),\n",
       " (11, 2.5),\n",
       " (13, 3.0),\n",
       " (4, 5.0),\n",
       " (50, 2.0),\n",
       " (19, 1.0),\n",
       " (15, 3.0),\n",
       " (8, 1.5),\n",
       " (9, 3.0),\n",
       " (14, 1.0),\n",
       " (19, 7.0),\n",
       " (15, 1.0),\n",
       " (18, 2.5),\n",
       " (12, 2.5),\n",
       " (8, 3.5),\n",
       " (25, 3.5),\n",
       " (14, 3.0),\n",
       " (5, 3.0),\n",
       " (31, 1.5),\n",
       " (6, 1.0),\n",
       " (11, 2.0),\n",
       " (9, 2.5),\n",
       " (10, 6.0),\n",
       " (8, 3.0),\n",
       " (10, 2.5),\n",
       " (11, 1.6666666666666667),\n",
       " (18, 2.0),\n",
       " (19, 5.0),\n",
       " (6, 3.0),\n",
       " (11, 1.0),\n",
       " (16, 2.0),\n",
       " (10, 3.0),\n",
       " (7, 3.5),\n",
       " (15, 5.0),\n",
       " (26, 2.0),\n",
       " (14, 3.0),\n",
       " (29, 3.0),\n",
       " (19, 3.5),\n",
       " (6, 1.0),\n",
       " (20, 1.0),\n",
       " (9, 4.5),\n",
       " (28, 6.0),\n",
       " (21, 1.3333333333333333),\n",
       " (9, 1.0),\n",
       " (6, 2.5),\n",
       " (5, 3.5),\n",
       " (22, 3.5),\n",
       " (15, 5.0),\n",
       " (17, 7.0),\n",
       " (16, 1.6666666666666667),\n",
       " (15, 3.03448275862069),\n",
       " (19, 3.5),\n",
       " (10, 4.0),\n",
       " (25, 3.880952380952381),\n",
       " (15, 2.5),\n",
       " (22, 3.5),\n",
       " (12, 1.0),\n",
       " (10, 2.5),\n",
       " (9, 2.0),\n",
       " (32, 3.0),\n",
       " (13, 5.0),\n",
       " (21, 3.0),\n",
       " (27, 5.0),\n",
       " (22, 4.0),\n",
       " (13, 2.0),\n",
       " (7, 6.0),\n",
       " (17, 4.0),\n",
       " (6, 1.0),\n",
       " (20, 3.5),\n",
       " (8, 2.0),\n",
       " (38, 6.0),\n",
       " (10, 2.375),\n",
       " (6, 3.0),\n",
       " (10, 4.0),\n",
       " (10, 2.5),\n",
       " (14, 2.0),\n",
       " (6, 1.0),\n",
       " (6, 2.0),\n",
       " (19, 3.0),\n",
       " (34, 2.631578947368421),\n",
       " (14, 1.5),\n",
       " (14, 2.0),\n",
       " (9, 3.0),\n",
       " (25, 2.976190476190476),\n",
       " (8, 2.0),\n",
       " (39, 2.5),\n",
       " (26, 2.0),\n",
       " (14, 2.0),\n",
       " (11, 3.0),\n",
       " (6, 2.0),\n",
       " (9, 2.5),\n",
       " (7, 2.5),\n",
       " (36, 3.21875),\n",
       " (11, 2.0),\n",
       " (6, 3.0),\n",
       " (8, 2.0),\n",
       " (12, 1.0),\n",
       " (12, 1.0),\n",
       " (7, 1.0),\n",
       " (8, 1.0),\n",
       " (22, 2.0),\n",
       " (4, 2.678571428571428),\n",
       " (11, 2.0),\n",
       " (29, 2.65625),\n",
       " (13, 3.0),\n",
       " (13, 1.5),\n",
       " (10, 3.5),\n",
       " (32, 6.0),\n",
       " (14, 3.0),\n",
       " (21, 5.0),\n",
       " (16, 3.0),\n",
       " (25, 2.0),\n",
       " (8, 1.3333333333333333),\n",
       " (8, 1.0),\n",
       " (20, 2.5),\n",
       " (30, 6.0),\n",
       " (48, 4.0),\n",
       " (6, 2.46875),\n",
       " (14, 1.0),\n",
       " (10, 3.0),\n",
       " (15, 2.0),\n",
       " (5, 4.5),\n",
       " (20, 3.615384615384615),\n",
       " (9, 2.0),\n",
       " (10, 2.3333333333333335),\n",
       " (15, 4.0),\n",
       " (18, 3.5),\n",
       " (8, 4.5),\n",
       " (14, 3.0),\n",
       " (37, 5.5),\n",
       " (13, 4.0),\n",
       " (9, 4.0),\n",
       " (28, 3.678571428571428),\n",
       " (22, 2.5),\n",
       " (6, 2.346153846153846),\n",
       " (13, 2.5),\n",
       " (11, 2.0),\n",
       " (7, 4.0),\n",
       " (14, 2.0),\n",
       " (14, 5.0),\n",
       " (11, 3.578947368421053),\n",
       " (9, 2.0),\n",
       " (12, 1.0),\n",
       " (13, 2.5),\n",
       " (11, 5.0),\n",
       " (26, 5.0),\n",
       " (11, 3.0),\n",
       " (5, 1.5),\n",
       " (10, 5.0),\n",
       " (34, 4.5),\n",
       " (8, 2.0),\n",
       " (30, 4.0),\n",
       " (18, 2.0),\n",
       " (4, 1.0),\n",
       " (13, 1.0),\n",
       " (27, 4.5),\n",
       " (9, 5.0),\n",
       " (21, 5.0),\n",
       " (6, 1.0),\n",
       " (24, 6.666666666666667),\n",
       " (5, 2.62962962962963),\n",
       " (15, 2.0),\n",
       " (10, 7.0),\n",
       " (8, 2.0),\n",
       " (11, 1.0),\n",
       " (25, 2.5),\n",
       " (27, 3.0),\n",
       " (18, 1.5),\n",
       " (17, 4.025),\n",
       " (7, 4.0),\n",
       " (28, 2.3333333333333335),\n",
       " (19, 2.0),\n",
       " (10, 2.5),\n",
       " (59, 3.67741935483871),\n",
       " (13, 3.0),\n",
       " (7, 3.5),\n",
       " (11, 2.0),\n",
       " (26, 3.105263157894737),\n",
       " (9, 2.3333333333333335),\n",
       " (23, 7.0),\n",
       " (24, 3.277777777777778),\n",
       " (9, 2.0),\n",
       " (22, 3.0),\n",
       " (23, 3.048780487804878),\n",
       " (13, 4.5),\n",
       " (11, 3.5),\n",
       " (12, 2.0),\n",
       " (12, 2.5),\n",
       " (20, 3.5),\n",
       " (6, 3.5),\n",
       " (26, 2.5),\n",
       " (29, 3.0),\n",
       " (8, 3.0),\n",
       " (13, 6.0),\n",
       " (10, 3.1875),\n",
       " (10, 2.0),\n",
       " (17, 3.0),\n",
       " (8, 2.0),\n",
       " (13, 2.576923076923077),\n",
       " (11, 2.0),\n",
       " (24, 3.103448275862069),\n",
       " (18, 2.0),\n",
       " (12, 1.5),\n",
       " (18, 2.0),\n",
       " (8, 1.0),\n",
       " (6, 2.0),\n",
       " (10, 6.0),\n",
       " (5, 3.5),\n",
       " (24, 7.0),\n",
       " (18, 4.0),\n",
       " (7, 1.0),\n",
       " (12, 1.3333333333333333),\n",
       " (18, 1.0),\n",
       " (8, 1.0),\n",
       " (9, 1.0),\n",
       " (20, 2.5),\n",
       " (12, 2.0),\n",
       " (16, 3.0),\n",
       " (12, 2.486486486486486),\n",
       " (15, 6.0),\n",
       " (13, 2.5),\n",
       " (13, 3.0),\n",
       " (13, 3.0),\n",
       " (14, 3.038461538461538),\n",
       " (8, 2.5),\n",
       " (10, 2.0),\n",
       " (18, 3.0),\n",
       " (50, 3.0),\n",
       " (5, 6.0),\n",
       " (15, 2.0),\n",
       " (10, 1.5),\n",
       " (27, 1.3333333333333333),\n",
       " (6, 2.0),\n",
       " (22, 3.0),\n",
       " (17, 1.0),\n",
       " (30, 4.5),\n",
       " (29, 2.0),\n",
       " (7, 1.0),\n",
       " (20, 3.5),\n",
       " (5, 3.5),\n",
       " (12, 3.5),\n",
       " (27, 3.658536585365854),\n",
       " (6, 1.0),\n",
       " (13, 1.0),\n",
       " (16, 3.0),\n",
       " (14, 2.0),\n",
       " (10, 1.0),\n",
       " (18, 6.0),\n",
       " (13, 2.827586206896552),\n",
       " (31, 5.0),\n",
       " (11, 4.0),\n",
       " (5, 2.0),\n",
       " (18, 1.0),\n",
       " (27, 2.421052631578947),\n",
       " (23, 3.5),\n",
       " (11, 1.5),\n",
       " (15, 3.27027027027027),\n",
       " (21, 3.5),\n",
       " (27, 3.157894736842105),\n",
       " (7, 1.3333333333333333),\n",
       " (27, 4.0),\n",
       " (7, 3.5),\n",
       " (5, 3.0),\n",
       " (7, 2.0),\n",
       " (8, 1.0),\n",
       " (18, 3.418604651162791),\n",
       " (14, 1.0),\n",
       " (11, 3.0),\n",
       " (21, 3.5),\n",
       " (21, 1.0),\n",
       " (6, 2.0),\n",
       " (14, 3.1875),\n",
       " (11, 2.0),\n",
       " (8, 3.0),\n",
       " (5, 1.0),\n",
       " (18, 6.0),\n",
       " (9, 4.0),\n",
       " (32, 7.0),\n",
       " (11, 3.0),\n",
       " (5, 2.666666666666667),\n",
       " (7, 4.0),\n",
       " (11, 5.0),\n",
       " (13, 4.0),\n",
       " (20, 1.6666666666666667),\n",
       " (7, 1.0),\n",
       " (11, 2.5),\n",
       " (6, 4.0),\n",
       " (6, 2.5),\n",
       " (45, 4.0),\n",
       " (11, 2.361111111111111),\n",
       " (12, 1.0),\n",
       " (12, 3.5),\n",
       " (12, 3.0),\n",
       " (21, 6.0),\n",
       " (31, 3.465116279069767),\n",
       " (12, 2.5),\n",
       " (12, 2.0),\n",
       " (19, 6.0),\n",
       " (26, 3.0),\n",
       " (15, 2.0),\n",
       " (22, 4.5),\n",
       " (8, 4.0),\n",
       " (21, 5.0),\n",
       " (6, 3.5),\n",
       " (11, 5.0),\n",
       " (25, 4.0),\n",
       " (14, 1.5),\n",
       " (10, 3.0),\n",
       " (12, 3.0),\n",
       " (15, 3.5),\n",
       " (16, 2.0),\n",
       " (20, 2.0),\n",
       " (8, 2.0),\n",
       " (19, 4.0),\n",
       " (10, 2.5),\n",
       " (25, 2.0),\n",
       " (12, 3.0),\n",
       " (12, 1.0),\n",
       " (10, 2.0),\n",
       " (9, 1.0),\n",
       " (11, 1.0),\n",
       " (26, 2.0),\n",
       " (12, 2.3333333333333335),\n",
       " (18, 3.0),\n",
       " (5, 2.0),\n",
       " (15, 4.0),\n",
       " (17, 3.0),\n",
       " (11, 3.0),\n",
       " (8, 5.0),\n",
       " (9, 3.0),\n",
       " (4, 3.0),\n",
       " (22, 2.0),\n",
       " (17, 3.0),\n",
       " (30, 3.24390243902439),\n",
       " (13, 2.65625),\n",
       " (10, 3.657894736842105),\n",
       " (21, 2.846153846153846),\n",
       " (37, 2.0),\n",
       " (17, 3.0),\n",
       " (23, 2.0),\n",
       " (32, 5.0),\n",
       " (42, 3.225806451612903),\n",
       " (29, 3.365853658536585),\n",
       " (12, 2.0),\n",
       " (19, 4.0),\n",
       " (22, 2.851851851851852),\n",
       " (7, 5.0),\n",
       " (7, 1.0),\n",
       " (6, 1.0),\n",
       " (12, 3.296296296296296),\n",
       " (30, 4.0),\n",
       " (31, 2.0),\n",
       " (19, 2.0),\n",
       " (17, 1.0),\n",
       " (8, 3.5),\n",
       " (10, 5.0),\n",
       " (6, 3.09375),\n",
       " (12, 4.0),\n",
       " (25, 2.0),\n",
       " (8, 4.0),\n",
       " (5, 1.0),\n",
       " (9, 2.0),\n",
       " (13, 1.0),\n",
       " (7, 2.0),\n",
       " (23, 4.5),\n",
       " (8, 4.0),\n",
       " (4, 3.0),\n",
       " (9, 1.0),\n",
       " (18, 3.0),\n",
       " (12, 2.0),\n",
       " (8, 2.3333333333333335),\n",
       " (26, 3.535714285714286),\n",
       " (22, 2.0),\n",
       " (7, 3.0),\n",
       " (8, 4.0),\n",
       " (6, 1.0),\n",
       " (6, 3.0),\n",
       " (5, 3.0),\n",
       " (7, 2.46875),\n",
       " (27, 1.0),\n",
       " (26, 5.0),\n",
       " (34, 2.535714285714286),\n",
       " (6, 3.0),\n",
       " (6, 5.0),\n",
       " (26, 3.027027027027027),\n",
       " (14, 2.0),\n",
       " (15, 2.5),\n",
       " (11, 1.0),\n",
       " (7, 3.0),\n",
       " (8, 3.5),\n",
       " (19, 4.0),\n",
       " (18, 3.0),\n",
       " (27, 3.0),\n",
       " (10, 2.0),\n",
       " (13, 3.5),\n",
       " (6, 2.0),\n",
       " (13, 4.5),\n",
       " (7, 3.0),\n",
       " (5, 2.0),\n",
       " (19, 1.6666666666666667),\n",
       " (7, 5.0),\n",
       " (17, 2.90625),\n",
       " (26, 2.5),\n",
       " (16, 1.0),\n",
       " (8, 2.5),\n",
       " (9, 4.0),\n",
       " (20, 3.0),\n",
       " (5, 2.5),\n",
       " (27, 3.78125),\n",
       " (16, 1.0),\n",
       " (12, 2.5),\n",
       " (11, 7.0),\n",
       " (24, 1.3333333333333333),\n",
       " (7, 1.0),\n",
       " (26, 3.0),\n",
       " (34, 3.1875),\n",
       " (10, 1.0),\n",
       " (16, 3.5),\n",
       " (29, 4.125),\n",
       " (16, 3.0),\n",
       " (15, 2.0),\n",
       " (13, 4.0),\n",
       " (6, 4.0),\n",
       " (13, 7.0),\n",
       " (34, 2.5),\n",
       " (17, 1.0),\n",
       " (16, 3.142857142857143),\n",
       " (13, 6.0),\n",
       " (11, 2.0),\n",
       " (10, 7.0),\n",
       " (21, 5.0),\n",
       " (6, 2.5),\n",
       " (15, 2.0),\n",
       " (18, 2.0),\n",
       " (7, 3.5),\n",
       " (14, 3.5),\n",
       " (14, 3.5),\n",
       " (20, 3.048780487804878),\n",
       " (21, 2.5),\n",
       " (8, 4.5),\n",
       " (18, 4.5),\n",
       " (16, 4.0),\n",
       " (22, 6.5),\n",
       " (11, 1.0),\n",
       " (8, 1.0),\n",
       " (8, 2.5),\n",
       " (6, 3.0),\n",
       " (7, 2.555555555555555),\n",
       " (7, 3.0),\n",
       " (7, 1.0),\n",
       " (11, 2.5),\n",
       " (40, 5.0),\n",
       " (7, 2.692307692307693),\n",
       " (15, 4.0),\n",
       " (20, 1.0),\n",
       " (4, 1.0),\n",
       " (11, 4.0),\n",
       " (11, 3.5),\n",
       " (17, 2.964285714285714),\n",
       " (9, 4.0),\n",
       " (9, 3.5),\n",
       " (7, 1.0),\n",
       " (12, 2.0),\n",
       " (12, 3.296296296296296),\n",
       " (9, 1.5),\n",
       " (5, 1.0),\n",
       " (12, 3.5),\n",
       " (17, 4.0),\n",
       " (15, 1.0),\n",
       " (18, 1.0),\n",
       " (22, 3.891891891891892),\n",
       " (8, 3.1875),\n",
       " (13, 2.0),\n",
       " (27, 4.0),\n",
       " (21, 3.5),\n",
       " (9, 4.0),\n",
       " (19, 5.5),\n",
       " (12, 2.0),\n",
       " (14, 2.0),\n",
       " (10, 6.0),\n",
       " (35, 2.0),\n",
       " (28, 2.0),\n",
       " (10, 2.53125),\n",
       " (17, 3.0),\n",
       " (5, 1.0),\n",
       " (7, 3.5),\n",
       " (10, 1.0),\n",
       " (26, 2.0),\n",
       " (8, 2.464285714285714),\n",
       " (22, 3.0),\n",
       " (5, 7.0),\n",
       " (6, 2.0),\n",
       " (6, 5.0),\n",
       " (14, 3.5),\n",
       " (16, 2.0),\n",
       " (13, 7.0),\n",
       " (7, 2.0),\n",
       " (18, 3.15625),\n",
       " (21, 1.0),\n",
       " (13, 2.0),\n",
       " (30, 4.0),\n",
       " (9, 5.0),\n",
       " (10, 3.0),\n",
       " (28, 2.0),\n",
       " (25, 3.0),\n",
       " (12, 7.0),\n",
       " (12, 2.0),\n",
       " (8, 4.0),\n",
       " (16, 2.5),\n",
       " (18, 3.634146341463415),\n",
       " (13, 5.0),\n",
       " (4, 3.5),\n",
       " (27, 3.023809523809524),\n",
       " (17, 3.0),\n",
       " (9, 4.0),\n",
       " (13, 6.0),\n",
       " (10, 2.5),\n",
       " (5, 5.0),\n",
       " (8, 4.5),\n",
       " (20, 7.0),\n",
       " (34, 3.5),\n",
       " (13, 2.5),\n",
       " (20, 2.72972972972973),\n",
       " (8, 1.0),\n",
       " (16, 2.324324324324324),\n",
       " (7, 2.0),\n",
       " (5, 3.0),\n",
       " (8, 2.5),\n",
       " (29, 1.0),\n",
       " (17, 1.0),\n",
       " (15, 5.0),\n",
       " (5, 3.5),\n",
       " (13, 1.5),\n",
       " (23, 1.0),\n",
       " (15, 2.5),\n",
       " (16, 1.6666666666666667),\n",
       " (10, 3.0),\n",
       " (9, 1.0),\n",
       " (17, 3.0),\n",
       " (17, 3.0),\n",
       " (10, 1.0),\n",
       " (17, 1.0),\n",
       " (5, 2.625),\n",
       " (7, 5.0),\n",
       " (18, 3.0),\n",
       " (10, 2.0),\n",
       " (16, 1.5),\n",
       " (10, 3.0),\n",
       " (23, 1.0),\n",
       " (8, 3.0),\n",
       " (13, 1.0),\n",
       " (61, 1.0),\n",
       " (8, 4.0),\n",
       " (16, 2.0),\n",
       " (23, 4.0),\n",
       " (28, 3.0),\n",
       " (6, 6.0),\n",
       " (4, 5.0),\n",
       " (10, 4.0),\n",
       " (9, 2.0),\n",
       " (30, 4.5),\n",
       " (16, 1.0),\n",
       " (17, 3.0),\n",
       " (5, 2.807692307692307),\n",
       " (11, 5.0),\n",
       " (13, 1.0),\n",
       " (19, 2.5),\n",
       " (5, 2.0),\n",
       " (4, 2.0),\n",
       " (23, 1.0),\n",
       " (7, 2.961538461538462),\n",
       " (13, 4.0),\n",
       " (4, 2.0),\n",
       " (6, 3.0),\n",
       " (11, 2.0),\n",
       " (18, 1.0),\n",
       " (9, 4.0),\n",
       " (8, 2.0),\n",
       " (7, 6.0),\n",
       " (8, 1.0),\n",
       " (8, 2.0),\n",
       " (15, 5.0),\n",
       " (15, 4.0),\n",
       " (17, 2.351351351351351),\n",
       " (12, 3.0),\n",
       " (8, 2.0),\n",
       " (18, 2.0),\n",
       " (6, 1.0),\n",
       " (9, 2.0),\n",
       " (14, 3.0),\n",
       " (12, 2.0),\n",
       " (14, 3.0),\n",
       " (15, 2.5),\n",
       " (5, 3.0),\n",
       " (9, 3.0),\n",
       " (20, 1.0),\n",
       " (16, 2.5),\n",
       " (10, 4.0),\n",
       " (22, 2.448275862068965),\n",
       " (7, 5.0),\n",
       " (21, 7.0),\n",
       " (12, 5.0),\n",
       " (7, 2.0),\n",
       " (4, 2.0),\n",
       " (11, 3.027027027027027),\n",
       " (13, 1.0),\n",
       " (14, 3.0),\n",
       " (11, 3.153846153846154),\n",
       " (14, 2.0),\n",
       " (6, 1.0),\n",
       " (17, 4.5),\n",
       " (13, 4.0),\n",
       " (8, 1.0),\n",
       " (6, 3.0),\n",
       " (37, 3.807692307692307),\n",
       " (11, 2.571428571428572),\n",
       " (26, 2.684210526315789),\n",
       " (24, 4.5),\n",
       " (13, 3.5),\n",
       " (12, 4.0),\n",
       " (6, 5.0),\n",
       " (20, 1.5),\n",
       " (16, 3.380952380952381),\n",
       " (7, 3.0),\n",
       " (15, 1.0),\n",
       " (8, 6.0),\n",
       " (25, 5.0),\n",
       " (9, 4.0),\n",
       " (5, 2.625),\n",
       " (8, 2.0),\n",
       " (13, 1.0),\n",
       " (39, 5.5),\n",
       " (26, 5.5),\n",
       " (20, 3.0),\n",
       " (6, 1.5),\n",
       " (7, 1.0),\n",
       " (7, 5.0),\n",
       " (12, 1.6666666666666667),\n",
       " (26, 4.0),\n",
       " (8, 2.1875),\n",
       " (10, 1.0),\n",
       " (6, 5.0),\n",
       " (16, 2.5),\n",
       " (25, 3.53125),\n",
       " (9, 3.0),\n",
       " (17, 4.0),\n",
       " (11, 4.0),\n",
       " (14, 5.0),\n",
       " (13, 5.0),\n",
       " (15, 2.5),\n",
       " (22, 2.0),\n",
       " (12, 2.0),\n",
       " (12, 2.0),\n",
       " (32, 3.0),\n",
       " (14, 2.0),\n",
       " (9, 1.0),\n",
       " (5, 2.0),\n",
       " (13, 2.0),\n",
       " (4, 5.0),\n",
       " (31, 5.0),\n",
       " (30, 1.5),\n",
       " (6, 4.0),\n",
       " (8, 6.0),\n",
       " (7, 2.035714285714286),\n",
       " (12, 2.5),\n",
       " (8, 2.0),\n",
       " (19, 2.0),\n",
       " (14, 2.3333333333333335),\n",
       " (10, 3.0),\n",
       " (6, 2.0),\n",
       " (7, 5.0),\n",
       " (36, 2.5),\n",
       " (10, 3.137931034482758),\n",
       " (23, 4.0),\n",
       " (8, 2.5),\n",
       " (16, 2.5),\n",
       " (6, 2.0),\n",
       " (23, 4.0),\n",
       " (11, 1.0),\n",
       " (22, 3.690476190476191),\n",
       " (12, 2.0),\n",
       " (18, 3.0),\n",
       " (13, 4.0),\n",
       " (15, 7.0),\n",
       " (16, 3.0),\n",
       " (13, 2.0),\n",
       " (8, 4.0),\n",
       " (11, 3.0),\n",
       " (14, 1.0),\n",
       " (24, 2.0),\n",
       " (19, 3.0),\n",
       " (21, 5.0),\n",
       " (20, 3.5),\n",
       " (31, 3.186046511627907),\n",
       " (20, 4.0),\n",
       " (10, 4.0),\n",
       " (5, 3.5),\n",
       " (11, 1.0),\n",
       " (13, 5.0),\n",
       " (13, 1.0),\n",
       " (15, 3.607142857142857),\n",
       " (9, 1.5),\n",
       " (26, 3.289473684210526),\n",
       " (8, 1.0),\n",
       " (4, 2.375),\n",
       " (8, 1.0),\n",
       " (37, 5.0),\n",
       " (25, 5.0625),\n",
       " (29, 7.0),\n",
       " (35, 3.0),\n",
       " (11, 2.0),\n",
       " (11, 1.0),\n",
       " (6, 4.0),\n",
       " (19, 1.0),\n",
       " (14, 5.0),\n",
       " (5, 2.0),\n",
       " (15, 3.0),\n",
       " (10, 3.5),\n",
       " (45, 3.483870967741935),\n",
       " (4, 2.90625),\n",
       " (9, 1.0),\n",
       " (17, 3.0),\n",
       " (7, 2.0),\n",
       " (24, 4.5),\n",
       " (9, 6.0),\n",
       " (15, 1.0),\n",
       " (32, 3.0),\n",
       " (68, 3.419354838709677),\n",
       " ...]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# Word tokenizer and sentence tokenizer with NLTK\n",
    "resp_lengths = []\n",
    "length_scores_spatiotemp = []\n",
    "length_scores_obj = []\n",
    "for row in ldh.itertuples():\n",
    "    if row.Index == 0:\n",
    "        continue\n",
    "    response = row.response\n",
    "    try:\n",
    "        score_spat = float(row.spatiotemp)\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        score_obj = float(row.obj)\n",
    "    except:\n",
    "        continue\n",
    "    len_response = len(word_tokenize(response))\n",
    "    resp_lengths.append(len_response)\n",
    "    length_scores_spatiotemp.append((len_response, score_spat))\n",
    "    length_scores_obj.append((len_response, score_obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split LDH Data into a training dataset and a validation dataset.\n",
    "train_ldh, val_ldh = train_test_split(ldh, test_size=0.15) # shuffle\n",
    "train_ldh_ds = Dataset.from_pandas(train_ldh)\n",
    "val_ldh_ds = Dataset.from_pandas(val_ldh)\n",
    "# TODO: Convert to DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/Users/danielpham/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3)\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "# For testing on a CPU, just grab the first few.\n",
    "if IS_GPU:\n",
    "    splits = [ReadInstruction('train'), ReadInstruction('test')]\n",
    "else:\n",
    "    splits = [ReadInstruction('train', to=256, unit=\"abs\"), ReadInstruction('test', to=64, unit=\"abs\")]\n",
    "\n",
    "train_ds, eval_ds = load_dataset('imdb', split=splits)\n",
    "\n",
    "# Split training data into model training and model validation\n",
    "train_val_ds = train_ds.train_test_split(test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmoBank Dataset Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/danielpham/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3/cache-30641a4e352f1b55.arrow\n",
      "Loading cached processed dataset at /Users/danielpham/.cache/huggingface/datasets/imdb/plain_text/1.0.0/90099cb476936b753383ba2ae6ab2eae419b2e87f71cd5189cb9c8e5814d12a3/cache-e144e067c2fcff59.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'train': ['attention_mask', 'input_ids', 'label'],\n",
       "  'test': ['attention_mask', 'input_ids', 'label']},\n",
       " {'train': (217, 3), 'test': (39, 3)})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "\n",
    "# Tokenize the datasets.\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)\n",
    "encoded_ds= train_val_ds.map(\n",
    "    lambda batch: tokenizer(\n",
    "        batch['text'],\n",
    "        add_special_tokens=True,\n",
    "        padding=True,\n",
    "        truncation=True), \n",
    "    batched=True, batch_size=16, remove_columns=['text'])\n",
    "\n",
    "# Reformat the dataset to PyTorch tensors.\n",
    "encoded_ds.set_format(type='torch')\n",
    "encoded_ds.column_names, encoded_ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DistilBertModel\n",
    "\n",
    "from ReappModel import ReappModel\n",
    "\n",
    "# Create the training model.\n",
    "# TODO: Suppress initialization errors.\n",
    "model = ReappModel(PRETRAINED_MODEL_NAME)\n",
    "\n",
    "num_train_epochs = 3 if IS_GPU else 1\n",
    "\n",
    "# Define the parameters under which the model will be trained.\n",
    "# By default, uses an AdamW optimizer w/ linear warmup.\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    ")\n",
    "\n",
    "encoded_train = encoded_ds['train']\n",
    "encoded_test  = encoded_ds['test']\n",
    "\n",
    "# HyperParameter search depending on the model.\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,                  \n",
    "    train_dataset=encoded_train,      \n",
    "    eval_dataset=encoded_test         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielpham/.local/share/virtualenvs/reapp-eSEM1IUs/lib/python3.8/site-packages/datasets/arrow_dataset.py:851: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.tensor(x, **format_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 06:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14, training_loss=0.2399845634187971, metrics={'train_runtime': 442.7938, 'train_samples_per_second': 0.032, 'total_flos': 0, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation: Parse the TrainOutput Object "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
